{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suffering-hebrew",
   "metadata": {},
   "source": [
    "# Activity classification problem using the UCI HAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "from tensorflow.math import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-treatment",
   "metadata": {},
   "source": [
    "## Open raw acceleration and gyroscope data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-niagara",
   "metadata": {},
   "source": [
    "Does not need to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "# raw body acceleration\n",
    "raw_body_acc_x_train = pd.read_csv('data/UCIHARDataset/train/Inertial Signals/body_acc_x_train.txt', \n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "raw_body_acc_y_train = pd.read_csv('data/UCIHARDataset/train/Inertial Signals/body_acc_y_train.txt',\n",
    "                                  delim_whitespace=True,\n",
    "                                  header=None)\n",
    "raw_body_acc_z_train = pd.read_csv('data/UCIHARDataset/train/Inertial Signals/body_acc_z_train.txt',\n",
    "                                  delim_whitespace=True,\n",
    "                                  header=None)\n",
    "# raw body gyroscope\n",
    "raw_body_gyro_x_train = pd.read_csv('data/UCIHARDataset/train/Inertial Signals/body_gyro_x_train.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "raw_body_gyro_y_train = pd.read_csv('data/UCIHARDataset/train/Inertial Signals/body_gyro_y_train.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "raw_body_gyro_z_train = pd.read_csv('data/UCIHARDataset/train/Inertial Signals/body_gyro_z_train.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "# raw total acceleration\n",
    "raw_total_acc_x_train = pd.read_csv('data/UCIHARDataset/train/Inertial Signals/total_acc_x_train.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "raw_total_acc_y_train = pd.read_csv('data/UCIHARDataset/train/Inertial Signals/total_acc_y_train.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "raw_total_acc_z_train = pd.read_csv('data/UCIHARDataset/train/Inertial Signals/total_acc_z_train.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "# Put the x_train references in an array\n",
    "X_train = [raw_body_acc_x_train, raw_body_acc_y_train, raw_body_acc_z_train, \n",
    "           raw_body_gyro_x_train, raw_body_gyro_y_train, raw_body_gyro_z_train,\n",
    "           raw_total_acc_x_train, raw_total_acc_y_train, raw_total_acc_z_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "# raw body acceleration\n",
    "raw_body_acc_x_test = pd.read_csv('data/UCIHARDataset/test/Inertial Signals/body_acc_x_test.txt',\n",
    "                                 delim_whitespace=True,\n",
    "                                 header=None)\n",
    "raw_body_acc_y_test = pd.read_csv('data/UCIHARDataset/test/Inertial Signals/body_acc_y_test.txt',\n",
    "                                 delim_whitespace=True,\n",
    "                                 header=None)\n",
    "\n",
    "raw_body_acc_z_test = pd.read_csv('data/UCIHARDataset/test/Inertial Signals/body_acc_z_test.txt',\n",
    "                                 delim_whitespace=True,\n",
    "                                 header=None)\n",
    "# raw body gyroscope\n",
    "raw_body_gyro_x_test = pd.read_csv('data/UCIHARDataset/test/Inertial Signals/body_gyro_x_test.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "raw_body_gyro_y_test = pd.read_csv('data/UCIHARDataset/test/Inertial Signals/body_gyro_y_test.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "raw_body_gyro_z_test = pd.read_csv('data/UCIHARDataset/test/Inertial Signals/body_gyro_z_test.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "# raw total acceleration\n",
    "raw_total_acc_x_test = pd.read_csv('data/UCIHARDataset/test/Inertial Signals/total_acc_x_test.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "raw_total_acc_y_test = pd.read_csv('data/UCIHARDataset/test/Inertial Signals/total_acc_y_test.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "raw_total_acc_z_test = pd.read_csv('data/UCIHARDataset/test/Inertial Signals/total_acc_z_test.txt',\n",
    "                                   delim_whitespace=True,\n",
    "                                   header=None)\n",
    "# Put the x_test references in an array\n",
    "X_test = [raw_body_acc_x_test, raw_body_acc_y_test, raw_body_acc_z_test, \n",
    "           raw_body_gyro_x_test, raw_body_gyro_y_test, raw_body_gyro_z_test,\n",
    "           raw_total_acc_x_test, raw_total_acc_y_test, raw_total_acc_z_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)\n",
    "print(X_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose to get 128 columns\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = X_train[i].transpose()\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] = X_test[i].transpose()\n",
    "print(X_train[0].shape)\n",
    "print(X_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    X_train[i][0].plot()\n",
    "plt.title('An instance of training data')\n",
    "plt.legend(['body_acc_x', 'body_acc_y', 'body_acc_z', \n",
    "            'body_gyro_x', 'body_gyro_y', 'body_gyro_z', \n",
    "            'total_acc_x', 'total_acc_y', 'total_acc_z'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_test)):\n",
    "    X_test[i][0].plot()  \n",
    "plt.title('An instance of testing data')\n",
    "plt.legend(['body_acc_x', 'body_acc_y', 'body_acc_z', \n",
    "            'body_gyro_x', 'body_gyro_y', 'body_gyro_z', \n",
    "            'total_acc_x', 'total_acc_y', 'total_acc_z'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X_train = X_train\n",
    "raw_X_test = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-power",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-nation",
   "metadata": {},
   "source": [
    "1. Walking\n",
    "2. Walking upstairs\n",
    "3. Walking downstairs\n",
    "4. Sitting\n",
    "5. Standing\n",
    "6. Laying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-january",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Walking', 'Walking U-S', 'Walking D-S', 'Sitting', 'Standing', 'Laying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for training data\n",
    "y_train = pd.read_csv('y_train.txt',\n",
    "                     delim_whitespace=True,\n",
    "                     header=None)\n",
    "# Results for testing data\n",
    "y_test = pd.read_csv('y_test.txt',\n",
    "                     delim_whitespace=True,\n",
    "                     header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all value to range[0, 5]\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See distribution of classes in training and testing\n",
    "train_classes = [0, 0, 0, 0, 0, 0]\n",
    "test_classes = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for index, row in y_train.iterrows():\n",
    "    train_classes[row[0]] += 1\n",
    "for index, row in y_test.iterrows():\n",
    "    test_classes[row[0]] += 1\n",
    "    \n",
    "print('Class distribution in training:\\t', train_classes)\n",
    "print('Class distribution in testing:\\t', test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentages\n",
    "for i in range(6):\n",
    "    print(classes[i])\n",
    "    print('\\tPercentage train:\\t', format(100 * train_classes[i] / (train_classes[i] + test_classes[i]), '.2f'), '%')\n",
    "    print('\\tPercentage test:\\t', format(100 * test_classes[i] / (train_classes[i] + test_classes[i]), '.2f'), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-serbia",
   "metadata": {},
   "source": [
    "## Beginning preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-winner",
   "metadata": {},
   "source": [
    "Plain dataset has absolutely no changes.\n",
    "Transformation 1 dataset has been changed using SigNorm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-jersey",
   "metadata": {},
   "source": [
    "Features (66 total) to have for each 128-length measurement:\n",
    "- mean (9)\n",
    "- median (9)\n",
    "- variance (9)\n",
    "- median absolute deviation (9)\n",
    "- rms (9)\n",
    "- difference of min and max (9)\n",
    "- xy magnitude (using dif of min and max x, and dif of min and max y) (3)\n",
    "- yz magnitude (3)\n",
    "- xz magnitude (3)\n",
    "- xyz magnitude (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute features\n",
    "def getFeatures(train, test):\n",
    "    \"\"\"\n",
    "        Takes in the arrays of training data and testing data \n",
    "        and returns the completed dataset with features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate means\n",
    "    means_train = pd.DataFrame()\n",
    "    means_test = pd.DataFrame()\n",
    "    mean_labels = ['body_acc_x_mean', 'body_acc_y_mean', 'body_acc_z_mean', \n",
    "                   'body_gyro_x_mean', 'body_gyro_y_mean', 'body_gyro_z_mean', \n",
    "                   'total_acc_x_mean', 'total_acc_y_mean', 'total_acc_z_mean']\n",
    "    for i in range(9):\n",
    "        means_train[mean_labels[i]] = train[i].mean()\n",
    "        means_test[mean_labels[i]] = test[i].mean()\n",
    "    \n",
    "    # calculate medians\n",
    "    med_train = pd.DataFrame()\n",
    "    med_test = pd.DataFrame()\n",
    "    med_labels = ['body_acc_x_med', 'body_acc_y_med', 'body_acc_z_med', \n",
    "                   'body_gyro_x_med', 'body_gyro_y_med', 'body_gyro_z_med', \n",
    "                   'total_acc_x_med', 'total_acc_y_med', 'total_acc_z_med']\n",
    "    for i in range(9):\n",
    "        med_train[med_labels[i]] = train[i].median()\n",
    "        med_test[med_labels[i]] = test[i].median()\n",
    "    \n",
    "    # calculate variance\n",
    "    sd_train = pd.DataFrame()\n",
    "    sd_test = pd.DataFrame()\n",
    "    sd_labels = ['body_acc_x_var', 'body_acc_y_var', 'body_acc_z_var', \n",
    "                 'body_gyro_x_var', 'body_gyro_y_var', 'body_gyro_z_var', \n",
    "                 'total_acc_x_var', 'total_acc_y_var', 'total_acc_z_var']\n",
    "    for i in range(9):\n",
    "        sd_train[sd_labels[i]] = train[i].var()\n",
    "        sd_test[sd_labels[i]] = test[i].var()\n",
    "        \n",
    "    # calculate median absolute deviation\n",
    "    mad_train = pd.DataFrame()\n",
    "    mad_test = pd.DataFrame()\n",
    "    mad_labels = ['body_acc_x_mad', 'body_acc_y_mad', 'body_acc_z_mad', \n",
    "                  'body_gyro_x_mad', 'body_gyro_y_mad', 'body_gyro_z_mad', \n",
    "                  'total_acc_x_mad', 'total_acc_y_mad', 'total_acc_z_mad']\n",
    "    for i in range(9):\n",
    "        mad_train[mad_labels[i]] = train[i].mad()\n",
    "        mad_test[mad_labels[i]] = test[i].mad()\n",
    "        \n",
    "    # calculate root-mean-square\n",
    "    rms_train = pd.DataFrame()\n",
    "    rms_test = pd.DataFrame()\n",
    "    rms_labels = ['body_acc_x_rms', 'body_acc_y_rms', 'body_acc_z_rms', \n",
    "                  'body_gyro_x_rms', 'body_gyro_y_rms', 'body_gyro_z_rms', \n",
    "                  'total_acc_x_rms', 'total_acc_y_rms', 'total_acc_z_rms']\n",
    "    for i in range(9):\n",
    "        rms_train[rms_labels[i]] = np.sqrt(np.power(train[i], 2).sum() \n",
    "                                           / len(train[i].index))\n",
    "        rms_test[rms_labels[i]] = np.sqrt(np.power(test[i], 2).sum() \n",
    "                                          / len(test[i].index))\n",
    "        \n",
    "    # calculate max - min (dx, dy, dz)\n",
    "    dif_train = pd.DataFrame()\n",
    "    dif_test = pd.DataFrame()\n",
    "    dif_labels = ['body_acc_x_dif', 'body_acc_y_dif', 'body_acc_z_dif', \n",
    "                  'body_gyro_x_dif', 'body_gyro_y_dif', 'body_gyro_z_dif', \n",
    "                  'total_acc_x_dif', 'total_acc_y_dif', 'total_acc_z_dif']\n",
    "    for i in range(9):\n",
    "        dif_train[dif_labels[i]] = train[i].max() - train[i].min()\n",
    "        dif_test[dif_labels[i]] = test[i].max() - test[i].min()\n",
    "        \n",
    "    # calculate xy magnitude\n",
    "    xy_mag_train = pd.DataFrame()\n",
    "    xy_mag_test = pd.DataFrame()\n",
    "    mag_xy_labels = ['body_acc_xy_mag', 'body_gyro_xy_mag', 'total_acc_xy_mag']\n",
    "    # body_acc_xy_mag\n",
    "    # body_gyro_xy_mag\n",
    "    # total_acc_xy_mag\n",
    "    for i in range(3):\n",
    "        xy_mag_train[mag_xy_labels[i]] = np.sqrt(np.power(dif_train[dif_labels[(i * 3)]], 2) \n",
    "                                                 + np.power(dif_train[dif_labels[(i * 3) + 1]], 2))\n",
    "        xy_mag_test[mag_xy_labels[i]] = np.sqrt(np.power(dif_test[dif_labels[(i * 3)]], 2) \n",
    "                                                + np.power(dif_test[dif_labels[(i * 3) + 1]], 2))\n",
    "        \n",
    "    # calculate yz magnitude\n",
    "    yz_mag_train = pd.DataFrame()\n",
    "    yz_mag_test = pd.DataFrame()\n",
    "    mag_yz_labels = ['body_acc_yz_mag', 'body_gyro_yz_mag', 'total_acc_yz_mag']\n",
    "    # body_acc_yz_mag\n",
    "    # body_gyro_yz_mag\n",
    "    # total_acc_yz_mag\n",
    "    for i in range(3):\n",
    "        yz_mag_train[mag_yz_labels[i]] = np.sqrt(np.power(dif_train[dif_labels[(i * 3 + 1)]], 2) \n",
    "                                                 + np.power(dif_train[dif_labels[(i * 3 + 2)]], 2))\n",
    "        yz_mag_test[mag_yz_labels[i]] = np.sqrt(np.power(dif_test[dif_labels[(i * 3 + 1)]], 2) \n",
    "                                                + np.power(dif_test[dif_labels[(i * 3 + 2)]], 2))\n",
    "        \n",
    "    # calculate xz magnitude\n",
    "    xz_mag_train = pd.DataFrame()\n",
    "    xz_mag_test = pd.DataFrame()\n",
    "    mag_xz_labels = ['body_acc_xz_mag', 'body_gyro_xz_mag', 'total_acc_xz_mag']\n",
    "    # body_acc_xz_mag\n",
    "    # body_gyro_xz_mag\n",
    "    # total_acc_xz_mag\n",
    "    for i in range(3):\n",
    "        xz_mag_train[mag_xz_labels[i]] = np.sqrt(np.power(dif_train[dif_labels[(i * 3)]], 2) \n",
    "                                                 + np.power(dif_train[dif_labels[(i * 3 + 2)]], 2))\n",
    "        xz_mag_test[mag_xz_labels[i]] = np.sqrt(np.power(dif_test[dif_labels[(i * 3)]], 2) \n",
    "                                                 + np.power(dif_test[dif_labels[(i * 3 + 2)]], 2))\n",
    "        \n",
    "    # calculate xyz magnitude\n",
    "    xyz_mag_train = pd.DataFrame()\n",
    "    xyz_mag_test = pd.DataFrame()\n",
    "    mag_xyz_labels = ['body_acc_xyz_mag', 'body_gyro_xyz_mag', 'total_acc_xyz_mag']\n",
    "    # body_acc_xyz_mag\n",
    "    # body_gyro_xyz_mag\n",
    "    # total_acc_xyz_mag\n",
    "    for i in range(3):\n",
    "        xyz_mag_train[mag_xyz_labels[i]] = np.sqrt(np.power(dif_train[dif_labels[(i * 3)]], 2)\n",
    "                                                  + np.power(dif_train[dif_labels[(i * 3 + 1)]], 2)\n",
    "                                                  + np.power(dif_train[dif_labels[(i * 3 + 2)]], 2))\n",
    "        xyz_mag_test[mag_xyz_labels[i]] = np.sqrt(np.power(dif_test[dif_labels[(i * 3)]], 2)\n",
    "                                                 + np.power(dif_test[dif_labels[(i * 3 + 1)]], 2)\n",
    "                                                 + np.power(dif_test[dif_labels[(i * 3 + 2)]], 2))\n",
    "        \n",
    "    final_X_train = pd.concat([means_train, med_train, sd_train, mad_train, rms_train, dif_train, \n",
    "                               xy_mag_train, yz_mag_train, xz_mag_train, xyz_mag_train], axis = 1)\n",
    "    final_X_test = pd.concat([means_test, med_test, sd_test, mad_test, rms_test, dif_test, \n",
    "                              xy_mag_test, yz_mag_test, xz_mag_test, xyz_mag_test], axis = 1)\n",
    "        \n",
    "    return final_X_train, final_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = ['body_acc_x_mean', 'body_acc_y_mean', 'body_acc_z_mean',\n",
    "               'body_gyro_x_mean', 'body_gyro_y_mean', 'body_gyro_z_mean',\n",
    "               'total_acc_x_mean', 'total_acc_y_mean', 'total_acc_z_mean',\n",
    "               \n",
    "               'body_acc_x_med', 'body_acc_y_med', 'body_acc_z_med', \n",
    "               'body_gyro_x_med', 'body_gyro_y_med', 'body_gyro_z_med',\n",
    "               'total_acc_x_med', 'total_acc_y_med', 'total_acc_z_med',\n",
    "               \n",
    "               'body_acc_x_var', 'body_acc_y_var', 'body_acc_z_var',\n",
    "               'body_gyro_x_var', 'body_gyro_y_var', 'body_gyro_z_var',\n",
    "               'total_acc_x_var', 'total_acc_y_var', 'total_acc_z_var',\n",
    "               \n",
    "               'body_acc_x_mad', 'body_acc_y_mad', 'body_acc_z_mad', \n",
    "               'body_gyro_x_mad', 'body_gyro_y_mad', 'body_gyro_z_mad', \n",
    "               'total_acc_x_mad', 'total_acc_y_mad', 'total_acc_z_mad',\n",
    "               \n",
    "               'body_acc_x_rms', 'body_acc_y_rms', 'body_acc_z_rms',\n",
    "               'body_gyro_x_rms', 'body_gyro_y_rms', 'body_gyro_z_rms',\n",
    "               'total_acc_x_rms', 'total_acc_y_rms', 'total_acc_z_rms',\n",
    "               \n",
    "               'body_acc_x_dif', 'body_acc_y_dif', 'body_acc_z_dif',\n",
    "               'body_gyro_x_dif', 'body_gyro_y_dif', 'body_gyro_z_dif',\n",
    "               'total_acc_x_dif', 'total_acc_y_dif', 'total_acc_z_dif',\n",
    "               \n",
    "               'body_acc_xy_mag', 'body_gyro_xy_mag', 'total_acc_xy_mag',\n",
    "               \n",
    "               'body_acc_yz_mag', 'body_gyro_yz_mag', 'total_acc_yz_mag',\n",
    "               \n",
    "               'body_acc_xz_mag', 'body_gyro_xz_mag', 'total_acc_xz_mag', \n",
    "               \n",
    "               'body_acc_xyz_mag', 'body_gyro_xyz_mag', 'total_acc_xyz_mag']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-integral",
   "metadata": {},
   "source": [
    "## Plain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "plain_body_acc_x_train = pd.read_csv('plain_har_data/train_body_acc_x.csv')\n",
    "plain_body_acc_y_train = pd.read_csv('plain_har_data/train_body_acc_y.csv')\n",
    "plain_body_acc_z_train = pd.read_csv('plain_har_data/train_body_acc_z.csv')\n",
    "plain_body_gyro_x_train = pd.read_csv('plain_har_data/train_body_gyro_x.csv')\n",
    "plain_body_gyro_y_train = pd.read_csv('plain_har_data/train_body_gyro_y.csv')\n",
    "plain_body_gyro_z_train = pd.read_csv('plain_har_data/train_body_gyro_z.csv')\n",
    "plain_total_acc_x_train = pd.read_csv('plain_har_data/train_total_acc_x.csv')\n",
    "plain_total_acc_y_train = pd.read_csv('plain_har_data/train_total_acc_y.csv')\n",
    "plain_total_acc_z_train = pd.read_csv('plain_har_data/train_total_acc_z.csv')\n",
    "# Put the x_train references in an array\n",
    "plain_X_train = [plain_body_acc_x_train, plain_body_acc_y_train, plain_body_acc_z_train, \n",
    "                 plain_body_gyro_x_train, plain_body_gyro_y_train, plain_body_gyro_z_train,\n",
    "                 plain_total_acc_x_train, plain_total_acc_y_train, plain_total_acc_z_train]\n",
    "# Testing data\n",
    "plain_body_acc_x_test = pd.read_csv('plain_har_data/test_body_acc_x.csv')\n",
    "plain_body_acc_y_test = pd.read_csv('plain_har_data/test_body_acc_y.csv')\n",
    "plain_body_acc_z_test = pd.read_csv('plain_har_data/test_body_acc_z.csv')\n",
    "plain_body_gyro_x_test = pd.read_csv('plain_har_data/test_body_gyro_x.csv')\n",
    "plain_body_gyro_y_test = pd.read_csv('plain_har_data/test_body_gyro_y.csv')\n",
    "plain_body_gyro_z_test = pd.read_csv('plain_har_data/test_body_gyro_z.csv')\n",
    "plain_total_acc_x_test = pd.read_csv('plain_har_data/test_total_acc_x.csv')\n",
    "plain_total_acc_y_test = pd.read_csv('plain_har_data/test_total_acc_y.csv')\n",
    "plain_total_acc_z_test = pd.read_csv('plain_har_data/test_total_acc_z.csv')\n",
    "# Put the x_test references in an array\n",
    "plain_X_test = [plain_body_acc_x_test, plain_body_acc_y_test, plain_body_acc_z_test, \n",
    "                plain_body_gyro_x_test, plain_body_gyro_y_test, plain_body_gyro_z_test,\n",
    "                plain_total_acc_x_test, plain_total_acc_y_test, plain_total_acc_z_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(plain_X_train)):\n",
    "#    plain_X_train[i].iloc[:, 0].plot()\n",
    "#plt.title('An instance of training data')\n",
    "#plt.legend(['body_acc_x', 'body_acc_y', 'body_acc_z', \n",
    "#            'body_gyro_x', 'body_gyro_y', 'body_gyro_z', \n",
    "#            'total_acc_x', 'total_acc_y', 'total_acc_z'])\n",
    "#plt.show()\n",
    "#plain_X_train[0].iloc[:, 0].plot()\n",
    "#plt.title('body_acc_x')\n",
    "#plt.show()\n",
    "#plain_X_train[1].iloc[:, 0].plot()\n",
    "#plt.title('body_acc_y')\n",
    "#plt.show()\n",
    "#plain_X_train[2].iloc[:, 0].plot()\n",
    "#plt.title('body_acc_z')\n",
    "#plt.show()\n",
    "#plain_X_train[3].iloc[:, 6:10].plot()\n",
    "#plt.title('body_gyro_x')\n",
    "#plt.show()\n",
    "#plain_X_train[4].iloc[:, 6:10].plot()\n",
    "#plt.title('body_gyro_y')\n",
    "#plt.show()\n",
    "#plain_X_train[5].iloc[:, 6:10].plot()\n",
    "#plt.title('body_gyro_z')\n",
    "#plt.show()\n",
    "#plain_X_train[6].iloc[:, 6:10].plot()\n",
    "#plt.title('total_acc_x')\n",
    "#plt.show()\n",
    "#plain_X_train[7].iloc[:, 6:10].plot()\n",
    "#plt.title('total_acc_y')\n",
    "#plt.show()\n",
    "#plain_X_train[8].iloc[:, 6:10].plot()\n",
    "#plt.title('total_acc_z')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-brooks",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plain_X_train[0].iloc[:, 0:9].hist(alpha = 0.3) # X can be gaussian\n",
    "#plain_X_train[1].iloc[:, 0].hist(alpha = 0.3) # Y\n",
    "#plain_X_train[2].iloc[:, 0].hist(alpha = 0.3) # Z can be gaussian\n",
    "#plain_X_train[3].iloc[:, 0].hist(alpha = 0.3) # X can be gaussian\n",
    "#plain_X_train[4].iloc[:, 0].hist(alpha = 0.3) # Y can be gaussian\n",
    "#plain_X_train[5].iloc[:, 0].hist(alpha = 0.3) # Z\n",
    "#plain_X_train[6].iloc[:, 0].hist(alpha = 0.3) # X can be gaussian\n",
    "#plain_X_train[7].iloc[:, 0].hist(alpha = 0.3) # Y can be gaussian\n",
    "#plain_X_train[8].iloc[:, 0].hist(alpha = 0.3) # Z can be gaussian\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_X_train, plain_X_test = getFeatures(plain_X_train, plain_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plain_X_train.shape)\n",
    "print(plain_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand = StandardScaler()\n",
    "plain_X_train = pd.DataFrame(stand.fit_transform(plain_X_train), columns = all_columns)\n",
    "plain_X_test = pd.DataFrame(stand.fit_transform(plain_X_test), columns = all_columns)\n",
    "plain_X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape for CNN\n",
    "plain_X_train = plain_X_train.to_numpy()\n",
    "plain_X_train = plain_X_train.reshape(plain_X_train.shape[0], plain_X_train.shape[1], 1)\n",
    "plain_X_test = plain_X_test.to_numpy()\n",
    "plain_X_test = plain_X_test.reshape(plain_X_test.shape[0], plain_X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-ethernet",
   "metadata": {},
   "source": [
    "## Transformation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-crash",
   "metadata": {},
   "source": [
    "Steps\n",
    "\n",
    "1: Moving average filter 2 (t2)\n",
    "    \n",
    "    - All\n",
    "    - Improves precision for Walking, Walking Upstairs, and Walking Downstairs\n",
    "    - Less precision for Sitting and Standing\n",
    "\n",
    "2: Difference transformation for (t2a, t2b)\n",
    "    \n",
    "    - all body_acc_x, body_acc_y, body_acc_z\n",
    "    - improves Walking Upstairs and Walking Downstairs\n",
    "\n",
    "3: Yeo-Johnson and then difference transformation (t2c, t2d, t2e)\n",
    "    \n",
    "    - body_gyro_x, body_gyro_y, body_gyro_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "t1_body_acc_x_train = pd.read_csv('t1b/prep_train_body_acc_x.csv')\n",
    "t1_body_acc_y_train = pd.read_csv('t1a/prep_train_body_acc_y.csv')\n",
    "t1_body_acc_z_train = pd.read_csv('t1/prep_train_body_acc_z.csv')\n",
    "t1_body_gyro_x_train = pd.read_csv('t1c/prep_train_body_gyro_x.csv')\n",
    "t1_body_gyro_y_train = pd.read_csv('t1d/prep_train_body_gyro_y.csv')\n",
    "t1_body_gyro_z_train = pd.read_csv('t1e/prep_train_body_gyro_z.csv')\n",
    "t1_total_acc_x_train = pd.read_csv('t1/prep_train_total_acc_x.csv')\n",
    "t1_total_acc_y_train = pd.read_csv('t1/prep_train_total_acc_y.csv')\n",
    "t1_total_acc_z_train = pd.read_csv('t1/prep_train_total_acc_z.csv')\n",
    "# Put the x_train references in an array\n",
    "t1_X_train = [t1_body_acc_x_train, t1_body_acc_y_train, t1_body_acc_z_train, \n",
    "              t1_body_gyro_x_train, t1_body_gyro_y_train, t1_body_gyro_z_train,\n",
    "              t1_total_acc_x_train, t1_total_acc_y_train, t1_total_acc_z_train]\n",
    "# Testing data\n",
    "t1_body_acc_x_test = pd.read_csv('t1b/prep_test_body_acc_x.csv')\n",
    "t1_body_acc_y_test = pd.read_csv('t1a/prep_test_body_acc_y.csv')\n",
    "t1_body_acc_z_test = pd.read_csv('t1/prep_test_body_acc_z.csv')\n",
    "t1_body_gyro_x_test = pd.read_csv('t1c/prep_test_body_gyro_x.csv')\n",
    "t1_body_gyro_y_test = pd.read_csv('t1d/prep_test_body_gyro_y.csv')\n",
    "t1_body_gyro_z_test = pd.read_csv('t1e/prep_test_body_gyro_z.csv')\n",
    "t1_total_acc_x_test = pd.read_csv('t1/prep_test_total_acc_x.csv')\n",
    "t1_total_acc_y_test = pd.read_csv('t1/prep_test_total_acc_y.csv')\n",
    "t1_total_acc_z_test = pd.read_csv('t1/prep_test_total_acc_z.csv')\n",
    "# Put the x_test references in an array\n",
    "t1_X_test = [t1_body_acc_x_test, t1_body_acc_y_test, t1_body_acc_z_test, \n",
    "             t1_body_gyro_x_test, t1_body_gyro_y_test, t1_body_gyro_z_test,\n",
    "             t1_total_acc_x_test, t1_total_acc_y_test, t1_total_acc_z_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(t1_X_train)):\n",
    "    t1_X_train[i].iloc[:, 0].plot()\n",
    "plt.title('An instance of training data')\n",
    "plt.legend(['body_acc_x', 'body_acc_y', 'body_acc_z', \n",
    "            'body_gyro_x', 'body_gyro_y', 'body_gyro_z', \n",
    "            'total_acc_x', 'total_acc_y', 'total_acc_z'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1_X_train[2].iloc[:, 0:20].hist(alpha = 0.3) # X\n",
    "#t1_X_train[1].iloc[:, 0].hist(alpha = 0.3) # Y\n",
    "#t1_X_train[2].iloc[:, 0].hist(alpha = 0.3) # Z\n",
    "#t1_X_train[3].iloc[:, 0].hist(alpha = 0.3) # X\n",
    "#t1_X_train[4].iloc[:, 0].hist(alpha = 0.3) # Y\n",
    "#t1_X_train[5].iloc[:, 0].hist(alpha = 0.3) # Z\n",
    "#t1_X_train[6].iloc[:, 0].hist(alpha = 0.3) # X\n",
    "#t1_X_train[7].iloc[:, 0].hist(alpha = 0.3) # Y\n",
    "#t1_X_train[8].iloc[:, 0].hist(alpha = 0.3) # Z\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute features\n",
    "t1_X_train, t1_X_test = getFeatures(t1_X_train, t1_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-meaning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stand = StandardScaler()\n",
    "t1_X_train = pd.DataFrame(stand.fit_transform(t1_X_train), columns = all_columns)\n",
    "t1_X_test = pd.DataFrame(stand.fit_transform(t1_X_test), columns = all_columns)\n",
    "t1_X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_X_train = t1_X_train.to_numpy()\n",
    "t1_X_train = t1_X_train.reshape(t1_X_train.shape[0], t1_X_train.shape[1], 1)\n",
    "t1_X_test = t1_X_test.to_numpy()\n",
    "t1_X_test = t1_X_test.reshape(t1_X_test.shape[0], t1_X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-cycle",
   "metadata": {},
   "source": [
    "## Create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Convolutional base\n",
    "    model = models.Sequential([\n",
    "        layers.Conv1D(filters = 10, kernel_size = 20, activation = 'relu', input_shape = (plain_X_train.shape[1], plain_X_train.shape[2])),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.MaxPooling1D(pool_size = 4),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(32, activation = 'relu'),\n",
    "        layers.Dense(6, activation = 'softmax')     \n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer = \"adam\",\n",
    "             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "             metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = build_model()\n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-slave",
   "metadata": {},
   "source": [
    "## Test plain data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-interest",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                              mode = 'min', \n",
    "                                              patience = 5,\n",
    "                                              verbose = 1)\n",
    "\n",
    "plain_history = model0.fit(plain_X_train, y_train, \n",
    "                    epochs = EPOCHS, \n",
    "                    callbacks = [early_stop],\n",
    "                    validation_data = (plain_X_test, y_test),\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds0 = model0.predict(plain_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process output\n",
    "preds0_summarized = np.zeros(y_test.shape[0])\n",
    "# set the value of predictions_summarized as the index of the \n",
    "# max value of the column at predictions[i]\n",
    "for i in range(preds0.shape[0]):\n",
    "    preds0_summarized[i] = preds0[i].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-klein",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds0_summarized, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm0 = confusion_matrix(y_test, preds0_summarized, num_classes = 6).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "df_cm = pd.DataFrame(cm0, \n",
    "                     index = [i for i in classes], \n",
    "                     columns = [i for i in classes])\n",
    "df_cm\n",
    "plt.figure(figsize = (20,15))\n",
    "sn.set(font_scale=1.5)\n",
    "sn.heatmap(df_cm, annot=True, linewidths = 0.4, square = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-dover",
   "metadata": {},
   "source": [
    "## Test transormation 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-tracy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                              mode = 'min', \n",
    "                                              patience = 5,\n",
    "                                              verbose = 1)\n",
    "\n",
    "t1_history = model1.fit(t1_X_train, y_train, \n",
    "                    epochs = EPOCHS, \n",
    "                    callbacks = [early_stop],\n",
    "                    validation_data = (t1_X_test, y_test),\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = model1.predict(t1_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process output\n",
    "preds1_summarized = np.zeros(y_test.shape[0])\n",
    "# set the value of predictions_summarized as the index of the \n",
    "# max value of the column at predictions[i]\n",
    "for i in range(preds1.shape[0]):\n",
    "    preds1_summarized[i] = preds1[i].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-rates",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds1_summarized, target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "cm1 = confusion_matrix(y_test, preds1_summarized, num_classes = 6).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-italy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "df_cm = pd.DataFrame(cm1, \n",
    "                     index = [i for i in classes], \n",
    "                     columns = [i for i in classes])\n",
    "df_cm\n",
    "plt.figure(figsize = (20,15))\n",
    "sn.set(font_scale=1.5)\n",
    "sn.heatmap(df_cm, annot=True, linewidths = 0.4, square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-digit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
